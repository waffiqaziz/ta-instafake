{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80bb1345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import import_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b162f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data\"\n",
    "dataset_version = \"fake-v1.0\"\n",
    "\n",
    "fake_dataset = import_data(dataset_path, dataset_version).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74218f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1194 entries, 0 to 1193\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   user_media_count          1194 non-null   float64\n",
      " 1   user_follower_count       1194 non-null   float64\n",
      " 2   user_following_count      1194 non-null   float64\n",
      " 3   user_has_profil_pic       1194 non-null   float64\n",
      " 4   user_is_private           1194 non-null   float64\n",
      " 5   follower_following_ratio  1194 non-null   float64\n",
      " 6   user_biography_length     1194 non-null   float64\n",
      " 7   username_length           1194 non-null   float64\n",
      " 8   username_digit_count      1194 non-null   float64\n",
      " 9   is_fake                   1194 non-null   float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 93.4 KB\n"
     ]
    }
   ],
   "source": [
    "fake_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad227e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_media_count</th>\n",
       "      <th>user_follower_count</th>\n",
       "      <th>user_following_count</th>\n",
       "      <th>user_has_profil_pic</th>\n",
       "      <th>user_is_private</th>\n",
       "      <th>follower_following_ratio</th>\n",
       "      <th>user_biography_length</th>\n",
       "      <th>username_length</th>\n",
       "      <th>username_digit_count</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "      <td>1194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.596315</td>\n",
       "      <td>369.095477</td>\n",
       "      <td>744.261307</td>\n",
       "      <td>0.922948</td>\n",
       "      <td>0.657454</td>\n",
       "      <td>0.812195</td>\n",
       "      <td>22.847571</td>\n",
       "      <td>11.123953</td>\n",
       "      <td>0.495812</td>\n",
       "      <td>0.167504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>107.402157</td>\n",
       "      <td>372.775741</td>\n",
       "      <td>1032.526420</td>\n",
       "      <td>0.266786</td>\n",
       "      <td>0.474760</td>\n",
       "      <td>0.804559</td>\n",
       "      <td>33.492868</td>\n",
       "      <td>2.998135</td>\n",
       "      <td>1.212010</td>\n",
       "      <td>0.373582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>449.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839351</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.003664</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1058.000000</td>\n",
       "      <td>4492.000000</td>\n",
       "      <td>7497.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_media_count  user_follower_count  user_following_count  \\\n",
       "count       1194.000000          1194.000000           1194.000000   \n",
       "mean          57.596315           369.095477            744.261307   \n",
       "std          107.402157           372.775741           1032.526420   \n",
       "min            0.000000             0.000000              0.000000   \n",
       "25%            3.000000           152.000000            267.000000   \n",
       "50%           20.000000           304.000000            449.000000   \n",
       "75%           67.000000           481.000000            711.000000   \n",
       "max         1058.000000          4492.000000           7497.000000   \n",
       "\n",
       "       user_has_profil_pic  user_is_private  follower_following_ratio  \\\n",
       "count          1194.000000      1194.000000               1194.000000   \n",
       "mean              0.922948         0.657454                  0.812195   \n",
       "std               0.266786         0.474760                  0.804559   \n",
       "min               0.000000         0.000000                  0.000000   \n",
       "25%               1.000000         0.000000                  0.481885   \n",
       "50%               1.000000         1.000000                  0.839351   \n",
       "75%               1.000000         1.000000                  1.003664   \n",
       "max               1.000000         1.000000                 16.800000   \n",
       "\n",
       "       user_biography_length  username_length  username_digit_count  \\\n",
       "count            1194.000000      1194.000000           1194.000000   \n",
       "mean               22.847571        11.123953              0.495812   \n",
       "std                33.492868         2.998135              1.212010   \n",
       "min                 0.000000         5.000000              0.000000   \n",
       "25%                 0.000000         9.000000              0.000000   \n",
       "50%                 7.000000        11.000000              0.000000   \n",
       "75%                33.000000        13.000000              0.000000   \n",
       "max               150.000000        30.000000             10.000000   \n",
       "\n",
       "           is_fake  \n",
       "count  1194.000000  \n",
       "mean      0.167504  \n",
       "std       0.373582  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cced4f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "1189   -1.0\n",
      "1190   -1.0\n",
      "1191   -1.0\n",
      "1192   -1.0\n",
      "1193   -1.0\n",
      "Name: is_fake, Length: 1194, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = fake_dataset.drop('is_fake', axis=1)\n",
    "y = fake_dataset.is_fake\n",
    "\n",
    "# Convert y to {-1, 1}\n",
    "y = (y * 2) - 1\n",
    "print(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36e12cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import scipy.spatial.distance as dist\n",
    "\n",
    "class Linear(object):\n",
    "    def __call__(self, x, y):\n",
    "        return np.dot(x, y.T)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Linear kernel\"\n",
    "\n",
    "\n",
    "class Poly(object):\n",
    "    def __init__(self, degree=2):\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return np.dot(x, y.T) ** self.degree\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Poly kernel\"\n",
    "\n",
    "\n",
    "class RBF(object):\n",
    "    def __init__(self, gamma=0.1):\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        x = np.atleast_2d(x)\n",
    "        y = np.atleast_2d(y)\n",
    "        return np.exp(-self.gamma * dist.cdist(x, y) ** 2).flatten()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"RBF kernel\"\n",
    "    \n",
    "class BaseEstimator:\n",
    "    y_required = True\n",
    "    fit_required = True\n",
    "\n",
    "    def _setup_input(self, X, y=None):\n",
    "        \"\"\"Ensure inputs to an estimator are in the expected format.\n",
    "\n",
    "        Ensures X and y are stored as numpy ndarrays by converting from an\n",
    "        array-like object if necessary. Enables estimators to define whether\n",
    "        they require a set of y target values or not with y_required, e.g.\n",
    "        kmeans clustering requires no target labels and is fit against only X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Feature dataset.\n",
    "        y : array-like\n",
    "            Target values. By default is required, but if y_required = false\n",
    "            then may be omitted.\n",
    "        \"\"\"\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "\n",
    "        if X.size == 0:\n",
    "            raise ValueError(\"Got an empty matrix.\")\n",
    "\n",
    "        if X.ndim == 1:\n",
    "            self.n_samples, self.n_features = 1, X.shape\n",
    "        else:\n",
    "            self.n_samples, self.n_features = X.shape[0], np.prod(X.shape[1:])\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        if self.y_required:\n",
    "            if y is None:\n",
    "                raise ValueError(\"Missed required argument y\")\n",
    "\n",
    "            if not isinstance(y, np.ndarray):\n",
    "                y = np.array(y)\n",
    "\n",
    "            if y.size == 0:\n",
    "                raise ValueError(\"The targets array must be no-empty.\")\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._setup_input(X, y)\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "\n",
    "        if self.X is not None or not self.fit_required:\n",
    "            return self._predict(X)\n",
    "        else:\n",
    "            raise ValueError(\"You must call `fit` before `predict`\")\n",
    "\n",
    "    def _predict(self, X=None):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "np.random.seed(9999)\n",
    "class SVM(BaseEstimator):\n",
    "    def __init__(self, C=1.0, kernel=None, tol=1e-3, max_iter=100):\n",
    "        \"\"\"Support vector machines implementation using simplified SMO optimization.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        C : float, default 1.0\n",
    "        kernel : Kernel object\n",
    "        tol : float , default 1e-3\n",
    "        max_iter : int, default 100\n",
    "        \"\"\"\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        if kernel is None:\n",
    "            self.kernel = Linear()\n",
    "        else:\n",
    "            self.kernel = kernel\n",
    "\n",
    "        self.b = 0\n",
    "        self.alpha = None\n",
    "        self.K = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._setup_input(X, y)\n",
    "        self.K = np.zeros((self.n_samples, self.n_samples))\n",
    "        for i in range(self.n_samples):\n",
    "            self.K[:, i] = self.kernel(self.X, self.X[i, :])\n",
    "        self.alpha = np.zeros(self.n_samples)\n",
    "        self.sv_idx = np.arange(0, self.n_samples)\n",
    "        return self._train()\n",
    "\n",
    "    def _train(self):\n",
    "        iters = 0\n",
    "        while iters < self.max_iter:\n",
    "            iters += 1\n",
    "            alpha_prev = np.copy(self.alpha)\n",
    "\n",
    "            for j in range(self.n_samples):\n",
    "                # Pick random i\n",
    "                i = self.random_index(j)\n",
    "\n",
    "                eta = 2.0 * self.K[i, j] - self.K[i, i] - self.K[j, j]\n",
    "                if eta >= 0:\n",
    "                    continue\n",
    "                L, H = self._find_bounds(i, j)\n",
    "\n",
    "                # Error for current examples\n",
    "                e_i, e_j = self._error(i), self._error(j)\n",
    "\n",
    "                # Save old alphas\n",
    "                alpha_io, alpha_jo = self.alpha[i], self.alpha[j]\n",
    "\n",
    "                # Update alpha\n",
    "                self.alpha[j] -= (self.y[j] * (e_i - e_j)) / eta\n",
    "                self.alpha[j] = self.clip(self.alpha[j], H, L)\n",
    "\n",
    "                self.alpha[i] = self.alpha[i] + self.y[i] * self.y[j] * (alpha_jo - self.alpha[j])\n",
    "\n",
    "                # Find intercept\n",
    "                b1 = (\n",
    "                    self.b - e_i - self.y[i] * (self.alpha[i] - alpha_io) * self.K[i, i]\n",
    "                    - self.y[j] * (self.alpha[j] - alpha_jo) * self.K[i, j]\n",
    "                )\n",
    "                b2 = (\n",
    "                    self.b - e_j - self.y[j] * (self.alpha[j] - alpha_jo) * self.K[j, j]\n",
    "                    - self.y[i] * (self.alpha[i] - alpha_io) * self.K[i, j]\n",
    "                )\n",
    "                if 0 < self.alpha[i] < self.C:\n",
    "                    self.b = b1\n",
    "                elif 0 < self.alpha[j] < self.C:\n",
    "                    self.b = b2\n",
    "                else:\n",
    "                    self.b = 0.5 * (b1 + b2)\n",
    "\n",
    "            # Check convergence\n",
    "            diff = np.linalg.norm(self.alpha - alpha_prev)\n",
    "            if diff < self.tol:\n",
    "                break\n",
    "        logging.info(\"Convergence has reached after %s.\" % iters)\n",
    "\n",
    "        # Save support vectors index\n",
    "        self.sv_idx = np.where(self.alpha > 0)[0]\n",
    "\n",
    "    def _predict(self, X=None):\n",
    "        n = X.shape[0]\n",
    "        result = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            result[i] = np.sign(self._predict_row(X[i, :]))\n",
    "        return result\n",
    "\n",
    "    def _predict_row(self, X):\n",
    "        k_v = self.kernel(self.X[self.sv_idx], X)\n",
    "        return np.dot((self.alpha[self.sv_idx] * self.y[self.sv_idx]).T, k_v.T) + self.b\n",
    "\n",
    "    def clip(self, alpha, H, L):\n",
    "        if alpha > H:\n",
    "            alpha = H\n",
    "        if alpha < L:\n",
    "            alpha = L\n",
    "        return alpha\n",
    "\n",
    "    def _error(self, i):\n",
    "        \"\"\"Error for single example.\"\"\"\n",
    "        return self._predict_row(self.X[i]) - self.y[i]\n",
    "\n",
    "    def _find_bounds(self, i, j):\n",
    "        \"\"\"Find L and H such that L <= alpha <= H.\n",
    "        Also, alpha must satisfy the constraint 0 <= Î±lpha <= C.\n",
    "        \"\"\"\n",
    "        if self.y[i] != self.y[j]:\n",
    "            L = max(0, self.alpha[j] - self.alpha[i])\n",
    "            H = min(self.C, self.C - self.alpha[i] + self.alpha[j])\n",
    "        else:\n",
    "            L = max(0, self.alpha[i] + self.alpha[j] - self.C)\n",
    "            H = min(self.C, self.alpha[i] + self.alpha[j])\n",
    "        return L, H\n",
    "\n",
    "    def random_index(self, z):\n",
    "        i = z\n",
    "        while i == z:\n",
    "            i = np.random.randint(0, self.n_samples - 1)\n",
    "        return i\n",
    "    \n",
    "def unhot(function):\n",
    "    \"\"\"Convert one-hot representation into one column.\"\"\"\n",
    "\n",
    "    def wrapper(actual, predicted):\n",
    "        if len(actual.shape) > 1 and actual.shape[1] > 1:\n",
    "            actual = actual.argmax(axis=1)\n",
    "        if len(predicted.shape) > 1 and predicted.shape[1] > 1:\n",
    "            predicted = predicted.argmax(axis=1)\n",
    "        return function(actual, predicted)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "@unhot\n",
    "def classification_error(actual, predicted):\n",
    "    return (actual != predicted).sum() / float(actual.shape[0])\n",
    "\n",
    "\n",
    "@unhot\n",
    "def accuracy(actual, predicted):\n",
    "    return 1.0 - classification_error(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ec6f159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Convergence has reached after 20.\n",
      "INFO:root:Convergence has reached after 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy (RBF kernel): 0.8440111420612814\n",
      "Classification accuracy (Linear kernel): 0.21727019498607247\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def classification():\n",
    "    # Generate a random binary classification problem.\n",
    "    # X, y = make_classification(\n",
    "    #     n_samples=1200, n_features=10, n_informative=5, random_state=1111, n_classes=2, class_sep=1.75\n",
    "    # )\n",
    "  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1111)\n",
    "\n",
    "    for kernel in [RBF(gamma=0.1), Linear()]:\n",
    "        model = SVM(max_iter=500, kernel=kernel, C=0.6)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        print(\"Classification accuracy (%s): %s\" % (kernel, accuracy(y_test, predictions)))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    classification()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
